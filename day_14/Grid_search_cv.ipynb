{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "model= LinearRegression()\n",
    "\n",
    "# create the parameters list\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create a model\n",
    "model= RandomForestClassifier()\n",
    "\n",
    "# create the parameters list\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create a model\n",
    "model= KNeighborsClassifier()\n",
    "\n",
    "# create the parameters list\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create a model\n",
    "model= SVC()\n",
    "\n",
    "# create the parameters list\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create a model\n",
    "model= DecisionTreeClassifier()\n",
    "\n",
    "# create the parameters list\n",
    "print(model.get_params())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets do hyper parameter tunning for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "df= sns.load_dataset('titanic')\n",
    "\n",
    "#fill the nan values in the age col\n",
    "df['age']= df['age'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'fit_intercept': True}\n",
      "Best Score: -0.0033709951196183806\n"
     ]
    }
   ],
   "source": [
    "X= df['age']\n",
    "y= df['fare']\n",
    "\n",
    "# reshape X and y\n",
    "X= X.values.reshape(-1,1)\n",
    "y= y.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "# create a model\n",
    "model= LinearRegression()\n",
    "# define parameter grid\n",
    "param_grid= {'fit_intercept': [True, False]}\n",
    "\n",
    "# create GridSearchCV object\n",
    "grid_search= GridSearchCV(model, param_grid, cv=5) #scoring='r2')\n",
    "\n",
    "# fit the model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# print best parameters and score\n",
    "print('Best Parameters:' ,grid_search.best_params_)\n",
    "print('Best Score:' ,grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
       "       'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['survived'].shape\n",
    "# to check its null values of survived col\n",
    "df['survived'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Best Score: 0.6234282955414142\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df= sns.load_dataset('titanic')\n",
    "# fill the nan values of age col\n",
    "df['age']= df['age'].fillna(df['age'].mean())\n",
    "\n",
    "X= df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "X.isnull().sum()\n",
    "y=df['survived']\n",
    "\n",
    "# get dummies for the 'sex' col in X\n",
    "X= pd.get_dummies(X, columns=[\"sex\"])\n",
    "# X= pd.get_dummies(X)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model= KNeighborsClassifier()\n",
    "\n",
    "# grid parameters\n",
    "# param_grid= {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'weights': ['distance', 'uniform']}\n",
    "\n",
    "# instead writing are the neighbours we can use numpy as well\n",
    "param_grid ={'n_neighbors': np.arange(1,30,2), 'weights': ['distance','uniform']}  # np.arange mean from 1 to 40 with interval of 2\n",
    "#create GridSearchCV object \n",
    "grid_search= GridSearchCV(model, param_grid, cv=5 , scoring='f1')\n",
    "\n",
    "# fit the model\n",
    "grid_search.fit(X, y)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will do the same for Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 5, 'min_samples_split': 2}\n",
      "Best Score: 0.7375116925970873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df= sns.load_dataset('titanic')\n",
    "# fill the nan values of age col\n",
    "df['age']= df['age'].fillna(df['age'].mean())\n",
    "\n",
    "X= df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "X.isnull().sum()\n",
    "y=df['survived']\n",
    "\n",
    "# get dummies for the 'sex' col in X\n",
    "X= pd.get_dummies(X, columns=[\"sex\"])\n",
    "# X= pd.get_dummies(X)\n",
    "\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model= DecisionTreeClassifier()\n",
    "\n",
    "# grid parameters\n",
    "param_grid= {'max_depth': [3,5,7,None], 'min_samples_split': [2,3,4]}\n",
    "\n",
    "# instead writing are the neighbours we can use numpy as well\n",
    "# param_grid ={'n_neighbors': np.arange(1,30,2), 'weights': ['distance','uniform']}  # np.arange mean from 1 to 40 with interval of 2\n",
    "#create GridSearchCV object \n",
    "grid_search= GridSearchCV(model, param_grid, cv=5 , scoring='f1')\n",
    "\n",
    "# fit the model\n",
    "grid_search.fit(X, y)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model comparison using Gridsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary libraries\n",
    "# # import libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df = sns.load_dataset(\"titanic\")\n",
    "# X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "# y = df['survived']\n",
    "# X = pd.get_dummies(X, columns=['sex'])\n",
    "# X.age.fillna(value = X['age'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # models = [LogisticRegression(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier()]\n",
    "# # model_names = ['Logistic Regression', 'SVM', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "\n",
    "# # models_scores = []\n",
    "# # for model, model_name in zip(models, model_names):\n",
    "# #     model.fit(X_train, y_train)\n",
    "# #     y_pred = model.predict(X_test)\n",
    "# #     accuracy = accuracy_score(y_test, y_pred)\n",
    "# #     models_scores.append([model_name,accuracy])\n",
    "\n",
    "# # sorted_models = sorted(models_scores, key=lambda x: x[1], reverse=True)\n",
    "# # for model in sorted_models:\n",
    "# #     print(\"Accuracy Score: \",f'{model[0]} : {model[1]:.2f}')\n",
    "\n",
    "\n",
    "# # Accuracy Score:  Random Forest : 0.81\n",
    "# # Accuracy Score:  Decision Tree : 0.79\n",
    "# # Accuracy Score:  KNN : 0.76\n",
    "# # Accuracy Score:  Logistic Regression : 0.75\n",
    "# # Accuracy Score:  SVM : 0.74\n",
    "\n",
    "# models = [LogisticRegression(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier()]\n",
    "# model_names = ['Logistic Regression', 'SVM', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "# models_scores = []\n",
    "\n",
    "# # define the paramater grid\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'gamma': [10,1, 0.1],\n",
    "#     'kernel': ['linear','rbf']\n",
    "\n",
    "# }\n",
    "# # create the grid\n",
    "# grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "# grid.fit(X, y)\n",
    "# print(\"Best Parameters:{}\".format(grid.best_params_))\n",
    "# print(\"Best Cross_val_score:{:0.2f}\".format(grid.best_score_))\n",
    "\n",
    "# # for model, model_name in zip(models, model_names):\n",
    "# #     model.fit(X_train, y_train)\n",
    "# #     y_pred = model.predict(X_test)\n",
    "# #     Precision = precision_score(y_test, y_pred)\n",
    "# #     models_scores.append([model_name,Precision])\n",
    "\n",
    "# sorted_models = sorted(models_scores, key=lambda x: x[1], reverse=True)\n",
    "# for model in sorted_models:\n",
    "#     print(\"Precision Score: \", f'{model[0]} : {model[1]:.2f}')\n",
    "\n",
    "# # Precision Score:  Random Forest : 0.80\n",
    "# # Precision Score:  Decision Tree : 0.78\n",
    "# # Precision Score:  KNN : 0.75\n",
    "# # Precision Score:  Logistic Regression : 0.74\n",
    "# # Precision Score:  SVM : 0.73\n",
    "\n",
    "# # models = [LogisticRegression(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier()]\n",
    "# # model_names = ['Logistic Regression', 'SVM', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "# # models_scores = []\n",
    "# # for model, model_name in zip(models, model_names):\n",
    "# #     model.fit(X_train, y_train)\n",
    "# #     y_pred = model.predict(X_test)\n",
    "# #     Recall = recall_score(y_test, y_pred)\n",
    "# #     models_scores.append([model_name,Recall])\n",
    "\n",
    "# # sorted_models = sorted(models_scores, key=lambda x: x[1], reverse=True)\n",
    "# # for model in sorted_models:\n",
    "# #     print(\"Recall Score: \",f'{model[0]} : {model[1]:.2f}')\n",
    "\n",
    "# # Recall Score:  Random Forest : 0.74\n",
    "# # Recall Score:  Decision Tree : 0.72\n",
    "# # Recall Score:  KNN : 0.68\n",
    "# # Recall Score:  Logistic Regression : 0.67\n",
    "# # Recall Score:  SVM : 0.65\n",
    "\n",
    "# # models = [LogisticRegression(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier()]\n",
    "# # model_names = ['Logistic Regression', 'SVM', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "# # models_scores = []\n",
    "# # for model, model_name in zip(models, model_names):\n",
    "# #     model.fit(X_train, y_train)\n",
    "# #     y_pred = model.predict(X_test)\n",
    "# #     F1 = f1_score(y_test, y_pred)\n",
    "# #     models_scores.append([model_name,F1])\n",
    "\n",
    "# # sorted_models = sorted(models_scores, key=lambda x: x[1], reverse=True)\n",
    "# # for model in sorted_models:\n",
    "# #     print(\"F1 Score: \",f'{model[0]} : {model[1]:.2f}')\n",
    "\n",
    "# # F1 Score:  Random Forest : 0.77\n",
    "# # F1 Score:  Decision Tree : 0.75\n",
    "# # F1 Score:  KNN : 0.71\n",
    "# # F1 Score:  Logistic Regression : 0.70\n",
    "# # F1 Score:  SVM : 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest Score: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39;49mbest_score_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest Parameters: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mbest_params_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the titanic dataset (you can replace this with your own dataset)\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "y = df['survived']\n",
    "X = pd.get_dummies(X, columns=['sex'])\n",
    "X.age.fillna(value = X['age'].mean(), inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models and their hyperparameter grids for GridSearchCV\n",
    "models = {\n",
    "    'SVM': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each model and print the results\n",
    "for models, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "    params = model_info['params']\n",
    "    \n",
    "    grid_search = GridSearchCV(model, params, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Best Score: {model.best_score_}\")\n",
    "    print(f\"Best Parameters: {model.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
